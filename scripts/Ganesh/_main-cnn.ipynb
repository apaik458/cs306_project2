{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuing-enlargement",
   "metadata": {},
   "source": [
    "# Main Robot Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-copper",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "light-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line following\n",
    "import lfrobot\n",
    "\n",
    "# Camera\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "# Model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-preference",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coral-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc33fb7378d4cf095196830259dbfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera initialised\n",
      "Sign detection model loaded\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# def adjust_hue_bgr8_to_jpeg(frame, hue_shift=0):\n",
    "#     # Convert BGR to HSV\n",
    "#     hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "#     # Modify the hue channel (H channel)\n",
    "#     hsv[..., 0] = (hsv[..., 0].astype(int) + hue_shift) % 10\n",
    "#     # Convert back to BGR\n",
    "#     bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "#     # Convert BGR to JPEG bytes\n",
    "#     ret, jpeg = cv2.imencode('.jpg', bgr)\n",
    "#     return jpeg.tobytes()\n",
    "\n",
    "# Initialise camera\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image)\n",
    "print('Camera initialised')\n",
    "\n",
    "# Load sign detection model\n",
    "model = pickle.load('cnn_model.h5')\n",
    "print('Sign detection model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-reform",
   "metadata": {},
   "source": [
    "Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed0\n",
      "0\n",
      "stop\n",
      "speed0.1\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialise line following\n",
    "lfrobot.lfInit()\n",
    "print('\\nLine following initialised')\n",
    "\n",
    "lfrobot.lfStart()\n",
    "lfrobot.lfSpeed(0.1)\n",
    "turnSpeed = 0.25 #turn speeds between 0.15 and 0.25 work best\n",
    "lfrobot.lfTurnSpeed(turnSpeed)\n",
    "\n",
    "current_speed = 0.1\n",
    "\n",
    "# Using Variabls to store the state\n",
    "slowState = False\n",
    "stopState = False\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    ## CAMERA INPUT\n",
    "    test_img = camera.value\n",
    "\n",
    "    # Resize to CNN input size\n",
    "    test_img_resized = cv2.resize(test_img, (64, 64))\n",
    "\n",
    "    # Convert grayscale to RGB if needed\n",
    "    if test_img_resized.ndim == 2:\n",
    "        test_img_resized = np.stack([test_img_resized]*3, axis=-1)\n",
    "\n",
    "    # Normalize and add batch dimension\n",
    "    test_array = np.expand_dims(test_img_resized, axis=0) / 255.0\n",
    "\n",
    "    ## PREDICTION\n",
    "    prediction = model.predict(test_array)[0]  # prediction vector\n",
    "    prediction_index = (prediction > 0.75).nonzero()[0]  # high confidence indices\n",
    "\n",
    "    ## ACTION\n",
    "    if 1 in prediction_index:   # sheep\n",
    "        print('sheep')\n",
    "#         lfrobot.lfStop()\n",
    "        lfrobot.lfSpeed(0)\n",
    "\n",
    "    elif 0 in prediction_index: # green\n",
    "        print('green')\n",
    "        lfrobot.lfSpeed(0.1)\n",
    "        pass\n",
    "\n",
    "    elif 2 in prediction_index: # slow\n",
    "        print('slow')\n",
    "        slowState = True\n",
    "        stopState = False\n",
    "\n",
    "    elif 3 in prediction_index: # stop\n",
    "        print('stop')\n",
    "        stopState = True\n",
    "#         lfrobot.lfStop()\n",
    "        lfrobot.lfSpeed(0)\n",
    "        time.sleep(5)\n",
    "        lfrobot.lfSpeed(0.1)    \n",
    "        time.sleep(1)\n",
    "\n",
    "    elif 4 in prediction_index: # yellow\n",
    "        print('yellow')\n",
    "#         lfrobot.lfStop()\n",
    "        lfrobot.lfSpeed(0)\n",
    "\n",
    "    else:                       # free\n",
    "        print('free')\n",
    "        if slowState and not stopState:\n",
    "            lfrobot.lfSpeed(0.05)\n",
    "        else:\n",
    "            lfrobot.lfSpeed(0.1)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-australian",
   "metadata": {},
   "source": [
    "Deinitialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfrobot.lfDeinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfrobot.lfStop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
