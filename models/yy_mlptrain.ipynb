{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c49685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_absolute_error, precision_score, accuracy_score\n",
    "import os\n",
    "import pickle\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import tensorflow as tf\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "#model = MLPClassifier(random_state = 1, learning_rate_init=0.003 ,max_iter=10000)\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5c390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory path: c:\\Users\\makjo\\GithubPrograms\\cs306_project2\\dataset\\dataset_\n",
      "Data directory exists: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataDir = os.path.join('..', 'dataset', 'dataset_')\n",
    "\n",
    "# Verify the paths exist\n",
    "print(f\"Data directory path: {os.path.abspath(dataDir)}\")\n",
    "print(f\"Data directory exists: {os.path.isdir(dataDir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801f19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... category : free\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/Users/yukyunglee/Documents/GitHub/cs306_project2/dataset/dataset_\\\\free'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mloading... category : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m path=os.path.join(datadir,i)    \u001b[38;5;66;03m#working with file/directory paths, common pathname manipulations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     18\u001b[39m   img_array=imread(os.path.join(path,img))\n\u001b[32m     19\u001b[39m   img_resized=resize(img_array,(\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m,\u001b[32m3\u001b[39m))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/Users/yukyunglee/Documents/GitHub/cs306_project2/dataset/dataset_\\\\free'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import os\n",
    "flat_data_arr=[]\n",
    "target_arr=[]\n",
    "\n",
    "#else mount the drive and give path of the parent-folder containing all category images folders.\n",
    "datadir='./cs306_project2/dataset/ExtractedSet/dataset'  #path to the main data folder\n",
    "\n",
    "Categories=['free', 'green', 'sheep', 'slow', 'stop', 'yellow']\n",
    "\n",
    "for i in Categories:\n",
    "  print(f'loading... category : {i}')\n",
    "  path=os.path.join(datadir,i)    #working with file/directory paths, common pathname manipulations\n",
    "  for img in os.listdir(path):\n",
    "    img_array=imread(os.path.join(path,img))\n",
    "    img_resized=resize(img_array,(224,224,3))\n",
    "    flat_data_arr.append(img_resized.flatten())\n",
    "    target_arr.append(Categories.index(i))\n",
    "  print(f'loaded category:{i} successfully')\n",
    "flat_data=np.array(flat_data_arr)\n",
    "target=np.array(target_arr)\n",
    "df=pd.DataFrame(flat_data)\n",
    "df['Target']=target\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce63a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (2211, 150529)\n"
     ]
    }
   ],
   "source": [
    "picklePath = \"../DataFormating/DataFrame/testdataframe.pkl\"\n",
    "\n",
    "#Load in the pickled dataframe created in FormatData.ipynb\n",
    "with open(picklePath, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "#Show the shape of the dataframe\n",
    "print(\"Dataframe shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92af2ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted Successfully\n"
     ]
    }
   ],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=77,stratify=y)\n",
    "print('Splitted Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b86562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\makjo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configured\n",
      "Model Fitted\n",
      "Accuracy Score: 95.93679458239278%\n"
     ]
    }
   ],
   "source": [
    "# Model definition and application\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(224, 224)),  #making 2D array to 1D so 28*28 = 784 will be the new batch size\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  #each neurons with their own weight will calculate through the 784 batch and also add their bias.\n",
    "    tf.keras.layers.Dense(64, activation='relu'),                       #Final layer producing 10 outputs\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  #Final layer producing 6 outputs\n",
    "])\n",
    "\n",
    "print(\"Model Configured\")\n",
    "\n",
    "model.compile(optimizer='adam',   #Chooses Adam to update the model’s weights during training. Adam is a popular gradient descent method\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),   #Tells Keras how to measure “how wrong” the predictions are.\n",
    "              metrics=['accuracy'])\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(solver=\"lbfgs\", max_iter=3000)\n",
    ")\n",
    "#(train_images, train_labels), (test_images, test_labels) = df.load_data()\n",
    "#test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict_proba(x_test)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"Model Fitted\")\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score: \" + str(acc_score*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e3a5ff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X.ndim == \u001b[32m2\u001b[39m:  \n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m X.reshape((X.shape[\u001b[32m0\u001b[39m],) + img_shape)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m test_labels = \u001b[43mto_label_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m     19\u001b[39m test_images = to_images(x_test, IMG_SHAPE)   \u001b[38;5;66;03m# for left panel image display\u001b[39;00m\n\u001b[32m     23\u001b[39m predictions = model.predict_proba(x_test)         \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mto_label_indices\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_label_indices\u001b[39m(y):            \u001b[38;5;66;03m#standardise labels into a 1D array of integer class indices (sklearn APIs expect 1D labels)\u001b[39;00m\n\u001b[32m      7\u001b[39m     y = np.asarray(y)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (np.argmax(y, axis=\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m y.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'stop'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_SHAPE = (224, 224, 3)  \n",
    "\n",
    "def to_label_indices(y):            #standardise labels into a 1D array of integer class indices (sklearn APIs expect 1D labels)\n",
    "    y = np.asarray(y)\n",
    "    return (np.argmax(y, axis=1) if y.ndim == 2 else y.astype(int, copy=False))\n",
    "\n",
    "def to_images(X, img_shape):        #Get image tensors for visualisation\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 4:   # already (N (Batch size),H (Height),W (Width),C (Channels))\n",
    "        return X\n",
    "    if X.ndim == 2:  \n",
    "        return X.reshape((X.shape[0],) + img_shape)\n",
    "\n",
    "\n",
    "test_labels = to_label_indices(y_test)  \n",
    "test_images = to_images(x_test, IMG_SHAPE)   # for left panel image display\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict_proba(x_test)         \n",
    "class_names = list(model.classes_)                # ensure consistent class order\n",
    "\n",
    "\n",
    "def plot_image(i, pred_probs_i, labels, images, class_names=class_names):   #show the i-th image with a title summarising prediction vs truth (on left side)\n",
    "    true_idx = int(labels[i])\n",
    "    pred_idx = int(np.argmax(pred_probs_i))\n",
    "    if images is not None:\n",
    "        img = images[i]\n",
    "        plt.imshow(img.astype(np.uint8) if img.max() > 1.0 else img)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"No image available\", ha='center', va='center')\n",
    "    plt.axis('off')\n",
    "    title = f\"Pred: {class_names[pred_idx]} | True: {class_names[true_idx]}\"\n",
    "    plt.title(title, color=('blue' if pred_idx == true_idx else 'red'), fontsize=10)\n",
    "\n",
    "def plot_value_array(i, pred_probs_i, labels, class_names=class_names):        #bar chart of the predicted class probabilities for sample i (on right side)\n",
    "    true_idx = int(labels[i])\n",
    "    pred_idx = int(np.argmax(pred_probs_i))\n",
    "    bars = plt.bar(range(len(pred_probs_i)), pred_probs_i)\n",
    "    bars[pred_idx].set_color('red')\n",
    "    bars[true_idx].set_color('blue')\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.xticks(range(len(pred_probs_i)), class_names, rotation=45, ha='right')\n",
    "    plt.ylabel(\"probability\")\n",
    "\n",
    "\n",
    "i = 120  # choose any valid index\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.subplot(1,2,1); plot_image(i, predictions[i], test_labels, test_images, class_names)\n",
    "plt.subplot(1,2,2); plot_value_array(i, predictions[i], test_labels, class_names)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "y_pred_idx = np.argmax(predictions, axis=1)\n",
    "acc = (y_pred_idx == test_labels).mean()\n",
    "print(f\"Test accuracy: {acc*100:.2f}%\")\n",
    "print(\"Class order:\", class_names)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "x_Train, x_Test, y_Train, y_Test = train_test_split(x, y, test_size=0.2, random_state=77, stratify=y)\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=512, random_state=42)),   \n",
    "    (\"mlp\", MLPClassifier(hidden_layer_sizes=(1024,128), activation='relu', alpha=1e-3, batch_size=64, learning_rate_init=5e-4, \n",
    "                          early_stopping=True,\n",
    "                          n_iter_no_change=15,\n",
    "                          max_iter=400,\n",
    "                          random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(x_Train, y_Train)\n",
    "predictions = model.predict_proba(x_Test)\n",
    "print(\"Accuracy:\", accuracy_score(y_Test, predictions.argmax(1)))\n",
    "\n",
    "# Reuse the plotting cell above; just set:\n",
    "X_test, y_test = x_Test, y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Exported successfully to c:\\Users\\makjo\\GithubPrograms\\cs306_project2\\models\\nk_mlp_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#Export the trained model using pickle\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Use relative path in the models directory\n",
    "modelPath = \"yy_mlp_model.pkl\"  # Saves in current directory (models/)\n",
    "\n",
    "# OR use absolute path within your project\n",
    "# modelPath = os.path.join(os.getcwd(), \"nk_mlp_model.pkl\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(modelPath) if os.path.dirname(modelPath) else '.', exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(modelPath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model Exported successfully to {os.path.abspath(modelPath)}\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to save to {modelPath}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
